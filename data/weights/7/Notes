Udacity training/validation data

def fcn_model(inputs, num_classes):
    
    # Add Encoder Blocks
    l1 = encoder_block(inputs, 32, 2)
    l2 = encoder_block(l1, 128, 2)
    l2d = layers.Dropout(0.5)(l2)
    l3 = encoder_block(l2d, 512, 2)
    
    # Remember that with each encoder layer, the depth of your model (the number of filters) increases.

    # Add 1x1 Convolution layer using conv2d_batchnorm().
    l4 = conv2d_batchnorm(l3, 128, kernel_size=1, strides=1)
    
    # Add the same number of Decoder Blocks as the number of Encoder Blocks
    l5 = decoder_block(l4, l2, 64)
    l6 = decoder_block(l5, l1, 32)
    x = decoder_block(l6, inputs, 16)
    
    # The function returns the output layer of your model. "x" is the final layer obtained from the last decoder_block()
    return layers.Conv2D(num_classes, 1, activation='softmax', padding='same')(x)

learning_rate = 0.001
batch_size = 64
num_epochs = 50
#steps_per_epoch = 156  # 9987//64
#validation_steps = 39 # 2555//64
steps_per_epoch = 64  # 4131//64
validation_steps = 18 # 1184//64
workers = 2

loss: 0.0181 - val_loss: 0.0273

weight:       0.7382022471910112
final_IOU:    0.547183957614
final_score:  0.403932427137
